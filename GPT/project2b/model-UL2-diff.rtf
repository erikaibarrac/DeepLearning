{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 erikaibarra@MacBook-Pro-368 Desktop % diff model.py model_actual.py \
47,52c47\
<         ############################ UL2 Configuration ###############################################\
<         if config.ul2:\
<             self.register_buffer("bias", torch.ones(config.block_size, config.block_size).view(1, 1, config.block_size, config.block_size))\
<         \
<         elif not config.ul2:\
<             self.register_buffer("bias", torch.tril(torch.ones(config.block_size, config.block_size))\
---\
>         self.register_buffer("bias", torch.tril(torch.ones(config.block_size, config.block_size))\
118,119d112\
<         C.checkpoint = None\
<         C.ul2 = False\
127d119\
<         self.config = config\
161,177c153,157\
<        \
<         ################################ Config checkpoints #######################################################\
<         if config.checkpoint is not None:\
<             self.checkpoint = torch.load(config.checkpoint)\
<             self.transformer.load_state_dict(self.checkpoint['model_transformer'])\
<             self.iter_num = self.checkpoint['iter_num']\
<             self.checkpoint_num = self.checkpoint['checkpoint_num']\
<             self.saved_loss = self.checkpoint['saved_loss']\
<             self.lm_head.load_state_dict(self.checkpoint['model_lm_head'])\
<             \
<         else:\
<             # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\
<             self.checkpoint = None\
<             self.apply(self._init_weights)\
<             for pn, p in self.named_parameters():\
<                 if pn.endswith('c_proj.weight'):\
<                     torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\
---\
>         # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\
>         self.apply(self._init_weights)\
>         for pn, p in self.named_parameters():\
>             if pn.endswith('c_proj.weight'):\
>                 torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\
278,281d257\
<         \
<         ################################### If checkpoints, load them #################################################3##################\
<         if self.checkpoint:\
<             optimizer.load_state_dict(self.checkpoint['optimizer_state_dict']) \
302c278\
<             loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)  # Changed class!\
---\
>             loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\
334c310\
<         return idx\
\\ No newline at end of file\
---\
>         return idx}